import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession
from pyspark.ml import Pipeline
from pandas.plotting import scatter_matrix
from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler

class Exploitation:
    def __init__(self, data):
        self.data = data

    def show_scartter_plot(self, numeric_features):
        numeric_data = self.data.select(numeric_features).toPandas()
        axs = pd.plotting.scatter_matrix(numeric_data, figsize=(8, 8))
        n = len(numeric_data.columns)
        for i in range(n):
            v = axs[i, 0]
            v.yaxis.label.set_rotation(0)
            v.yaxis.label.set_ha('right')
            v.set_yticks(())
            h = axs[n-1, i]
            h.xaxis.label.set_rotation(90)
            h.set_xticks(())
        plt.savefig("plots_images/scartter_matrix.png")
        plt.close()

    def one_encoding_columns(self, categoricalColumns):
        stages = []
        for categoricalCol in categoricalColumns:
            stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')
            encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + "classVec"])
            stages += [stringIndexer, encoder]

        label_stringIdx = StringIndexer(inputCol = 'y', outputCol = 'label')
        stages += [label_stringIdx]
        numericCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']
        assemblerInputs = [c + "classVec" for c in categoricalColumns] + numericCols

        assembler = VectorAssembler(inputCols=assemblerInputs, outputCol="features")
        stages += [assembler]
        return stages

    def run(self):
        #Part des différentes targets
        self.data.groupby('y').count().toPandas()
        class_distribution = self.data.groupby('y').count().toPandas()
        sns.catplot(x="y", y="count", kind="bar", data=class_distribution)
        plt.savefig("plots_images/distribution.png")
        plt.close()

        #Description statistics
        numeric_features = [t[0] for t in self.data.dtypes if t[1] == 'int']
        self.data.select(numeric_features).describe().toPandas()
        #Show scartter plotting matrix
        self.show_scartter_plot(numeric_features)
        #Select numerical columns
        self;data = self.data.select('age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y')
        cols_num = self.data.columns

        #ENcode catégorical columns
        categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']
        #Apply a pipeline on catégorical columns
        stages = self.one_encoding_columns(categoricalColumns)

        pipeline = Pipeline(stages = stages)
        pipelineModel = pipeline.fit(self.data)
        self.data = pipelineModel.transform(self.data)
        selectedCols = ['label', 'features'] + cols_num
        self.data = self.data.select(selectedCols)

        #Split Dataset to train and test set
        self.train, self.test = self.data.randomSplit([0.7, 0.3], seed = 2018)
        print("Training Dataset Count: " + str(self.train.count()))
        print("Test Dataset Count: " + str(self.test.count()))
        return self.train, self.test
